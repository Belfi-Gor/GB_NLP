{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Lesson 7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI8xMHNMnGMu"
      },
      "source": [
        "# В предыдущей серии\n",
        "\n",
        "\n",
        "<img src=\"images/RNNCompar.png\"/>\n",
        "\n",
        "\n",
        "Мы посмотрели на задачу классификации текстов. Но есть ряд более сильных подходов, которые лучше показывать через задачу генерации\n",
        "\n",
        "\n",
        "# Генерация текстов, encoder-decoder\n",
        "\n",
        "<img src=\"images/EncDec.png\"/>\n",
        "\n",
        "\n",
        "Данная архитектура называется seq2seq, простыми словами выглядит она следующим образом:\n",
        "<img src=\"images/seq2seq.png\"/>\n",
        "\n",
        "\n",
        "эту модель можно строить на уровне слов и на уровне токенов. Попробуем обучить на уровне токенов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K1L7i0UnoGU",
        "outputId": "4037ede4-4888-4740-cca9-c28738c8e0ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJFmRDG7nGMz"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4n2ubXznGNC"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 30\n",
        "latent_dim = 256\n",
        "num_samples = 10000\n",
        "data_path = '/content/drive/My Drive/Нейронные сети/Neural Language Processing/Lesson 7/Lesson 07/data/fra-eng/fra.txt'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYGuZLXhnGNN"
      },
      "source": [
        "# Собираем из текстов токены и делаем pne-hot вектора на каждый токен\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeq0cMNynGNV"
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV6XmunynGNc"
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO2ijGtcnGNi"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
        "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXbPSA4nnGNp",
        "outputId": "befa00e7-fc59-438b-81b5-208ef0d1d1a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "for seq_index in range(100):\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "  1/125 [..............................] - ETA: 0s - loss: 4.5063 - accuracy: 0.0050WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0153s vs `on_train_batch_end` time: 0.0269s). Check your callbacks.\n",
            "125/125 [==============================] - 5s 43ms/step - loss: 1.3315 - accuracy: 0.7202 - val_loss: 1.0753 - val_accuracy: 0.6981\n",
            "Epoch 2/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.8882 - accuracy: 0.7548 - val_loss: 0.9204 - val_accuracy: 0.7528\n",
            "Epoch 3/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.7419 - accuracy: 0.7974 - val_loss: 0.7715 - val_accuracy: 0.7813\n",
            "Epoch 4/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.6366 - accuracy: 0.8196 - val_loss: 0.6903 - val_accuracy: 0.8019\n",
            "Epoch 5/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.5823 - accuracy: 0.8319 - val_loss: 0.6523 - val_accuracy: 0.8087\n",
            "Epoch 6/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.5472 - accuracy: 0.8410 - val_loss: 0.6185 - val_accuracy: 0.8197\n",
            "Epoch 7/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.5207 - accuracy: 0.8477 - val_loss: 0.5933 - val_accuracy: 0.8253\n",
            "Epoch 8/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.4996 - accuracy: 0.8538 - val_loss: 0.5788 - val_accuracy: 0.8299\n",
            "Epoch 9/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.4825 - accuracy: 0.8582 - val_loss: 0.5627 - val_accuracy: 0.8348\n",
            "Epoch 10/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.4674 - accuracy: 0.8621 - val_loss: 0.5486 - val_accuracy: 0.8398\n",
            "Epoch 11/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.4523 - accuracy: 0.8662 - val_loss: 0.5369 - val_accuracy: 0.8426\n",
            "Epoch 12/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.4396 - accuracy: 0.8698 - val_loss: 0.5231 - val_accuracy: 0.8463\n",
            "Epoch 13/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.4269 - accuracy: 0.8734 - val_loss: 0.5188 - val_accuracy: 0.8479\n",
            "Epoch 14/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.4148 - accuracy: 0.8771 - val_loss: 0.5080 - val_accuracy: 0.8503\n",
            "Epoch 15/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.4044 - accuracy: 0.8798 - val_loss: 0.5025 - val_accuracy: 0.8517\n",
            "Epoch 16/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.3938 - accuracy: 0.8826 - val_loss: 0.4939 - val_accuracy: 0.8540\n",
            "Epoch 17/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.3831 - accuracy: 0.8858 - val_loss: 0.4888 - val_accuracy: 0.8559\n",
            "Epoch 18/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.3741 - accuracy: 0.8885 - val_loss: 0.4818 - val_accuracy: 0.8568\n",
            "Epoch 19/30\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.3646 - accuracy: 0.8910 - val_loss: 0.4773 - val_accuracy: 0.8582\n",
            "Epoch 20/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.3558 - accuracy: 0.8935 - val_loss: 0.4793 - val_accuracy: 0.8602\n",
            "Epoch 21/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.3467 - accuracy: 0.8958 - val_loss: 0.4692 - val_accuracy: 0.8614\n",
            "Epoch 22/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.3380 - accuracy: 0.8986 - val_loss: 0.4651 - val_accuracy: 0.8630\n",
            "Epoch 23/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.3289 - accuracy: 0.9013 - val_loss: 0.4620 - val_accuracy: 0.8638\n",
            "Epoch 24/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.3210 - accuracy: 0.9038 - val_loss: 0.4564 - val_accuracy: 0.8659\n",
            "Epoch 25/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.3125 - accuracy: 0.9059 - val_loss: 0.4546 - val_accuracy: 0.8656\n",
            "Epoch 26/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.3068 - accuracy: 0.9080 - val_loss: 0.5333 - val_accuracy: 0.8463\n",
            "Epoch 27/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.4285 - accuracy: 0.8754 - val_loss: 0.4716 - val_accuracy: 0.8610\n",
            "Epoch 28/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.3329 - accuracy: 0.9001 - val_loss: 0.4580 - val_accuracy: 0.8647\n",
            "Epoch 29/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.3135 - accuracy: 0.9058 - val_loss: 0.4522 - val_accuracy: 0.8663\n",
            "Epoch 30/30\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.3018 - accuracy: 0.9096 - val_loss: 0.4505 - val_accuracy: 0.8676\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Courez-vous !\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Salut !\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Salut !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Sourez-vous !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Sourez-vous !\n",
            "\n",
            "-\n",
            "Input sentence: Who?\n",
            "Decoded sentence: Qui a de la maison ?\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Attends-moi !\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: Sous !\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: Sart-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: Sautez-moi !\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Atrends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Atrends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Atrends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Attends une !\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Attends une !\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Poussez-vous !\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Poussez-vous !\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Poussez-vous !\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Sallez-vous !\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Sallez-vous !\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: Je vous.\n",
            "\n",
            "-\n",
            "Input sentence: I try.\n",
            "Decoded sentence: J'ai le fait.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Je vais maintenant.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Je vais maintenant.\n",
            "\n",
            "-\n",
            "Input sentence: I won.\n",
            "Decoded sentence: J'ai parti.\n",
            "\n",
            "-\n",
            "Input sentence: Oh no!\n",
            "Decoded sentence: Tommends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: Attends un mon !\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: Attends un mon !\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Contiz-moi.\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Contiz-moi.\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Contiz-moi.\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Contiz-moi.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Donnez-le !\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Pass !\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Pass !\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Pass !\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Attrez de la maison.\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Attrez de la maison.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Tom ai ?\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Tom ai ?\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Tom ai ?\n",
            "\n",
            "-\n",
            "Input sentence: Hop in.\n",
            "Decoded sentence: Montez-le.\n",
            "\n",
            "-\n",
            "Input sentence: Hop in.\n",
            "Decoded sentence: Montez-le.\n",
            "\n",
            "-\n",
            "Input sentence: Hug me.\n",
            "Decoded sentence: Serre-moi de la mainter.\n",
            "\n",
            "-\n",
            "Input sentence: Hug me.\n",
            "Decoded sentence: Serre-moi de la mainter.\n",
            "\n",
            "-\n",
            "Input sentence: I fell.\n",
            "Decoded sentence: Je suis maintenant.\n",
            "\n",
            "-\n",
            "Input sentence: I fell.\n",
            "Decoded sentence: Je suis maintenant.\n",
            "\n",
            "-\n",
            "Input sentence: I know.\n",
            "Decoded sentence: Je sais les amintent.\n",
            "\n",
            "-\n",
            "Input sentence: I left.\n",
            "Decoded sentence: Je suis mange.\n",
            "\n",
            "-\n",
            "Input sentence: I left.\n",
            "Decoded sentence: Je suis mange.\n",
            "\n",
            "-\n",
            "Input sentence: I lied.\n",
            "Decoded sentence: J'ai ainte.\n",
            "\n",
            "-\n",
            "Input sentence: I lost.\n",
            "Decoded sentence: J'ai mainte.\n",
            "\n",
            "-\n",
            "Input sentence: I paid.\n",
            "Decoded sentence: J'ai partir.\n",
            "\n",
            "-\n",
            "Input sentence: I'm 19.\n",
            "Decoded sentence: J'ai un gante.\n",
            "\n",
            "-\n",
            "Input sentence: I'm OK.\n",
            "Decoded sentence: Je suis maintenant.\n",
            "\n",
            "-\n",
            "Input sentence: I'm OK.\n",
            "Decoded sentence: Je suis maintenant.\n",
            "\n",
            "-\n",
            "Input sentence: Listen.\n",
            "Decoded sentence: Gartez-le.\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: En aut en menter !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: En aut en menter !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: En aut en menter !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: En aut en menter !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: En aut en menter !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: En aut en menter !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: En aut en menter !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: En aut en menter !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: En aut en menter !\n",
            "\n",
            "-\n",
            "Input sentence: Really?\n",
            "Decoded sentence: Je me main ?\n",
            "\n",
            "-\n",
            "Input sentence: Really?\n",
            "Decoded sentence: Je me main ?\n",
            "\n",
            "-\n",
            "Input sentence: Really?\n",
            "Decoded sentence: Je me main ?\n",
            "\n",
            "-\n",
            "Input sentence: Thanks.\n",
            "Decoded sentence: Merci !\n",
            "\n",
            "-\n",
            "Input sentence: We try.\n",
            "Decoded sentence: Nous avons maintenant.\n",
            "\n",
            "-\n",
            "Input sentence: We won.\n",
            "Decoded sentence: Nous avons autentire.\n",
            "\n",
            "-\n",
            "Input sentence: We won.\n",
            "Decoded sentence: Nous avons autentire.\n",
            "\n",
            "-\n",
            "Input sentence: We won.\n",
            "Decoded sentence: Nous avons autentire.\n",
            "\n",
            "-\n",
            "Input sentence: We won.\n",
            "Decoded sentence: Nous avons autentire.\n",
            "\n",
            "-\n",
            "Input sentence: Ask Tom.\n",
            "Decoded sentence: Viens tout !\n",
            "\n",
            "-\n",
            "Input sentence: Awesome!\n",
            "Decoded sentence: Sans sentis !\n",
            "\n",
            "-\n",
            "Input sentence: Be calm.\n",
            "Decoded sentence: Soyez disten !\n",
            "\n",
            "-\n",
            "Input sentence: Be calm.\n",
            "Decoded sentence: Soyez disten !\n",
            "\n",
            "-\n",
            "Input sentence: Be calm.\n",
            "Decoded sentence: Soyez disten !\n",
            "\n",
            "-\n",
            "Input sentence: Be cool.\n",
            "Decoded sentence: Sois gante !\n",
            "\n",
            "-\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: Sois gante !\n",
            "\n",
            "-\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: Sois gante !\n",
            "\n",
            "-\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: Sois gante !\n",
            "\n",
            "-\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: Sois gante !\n",
            "\n",
            "-\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: Sois gante !\n",
            "\n",
            "-\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: Sois gante !\n",
            "\n",
            "-\n",
            "Input sentence: Be kind.\n",
            "Decoded sentence: Sois gentilles !\n",
            "\n",
            "-\n",
            "Input sentence: Be nice.\n",
            "Decoded sentence: Sois gentil !\n",
            "\n",
            "-\n",
            "Input sentence: Be nice.\n",
            "Decoded sentence: Sois gentil !\n",
            "\n",
            "-\n",
            "Input sentence: Be nice.\n",
            "Decoded sentence: Sois gentil !\n",
            "\n",
            "-\n",
            "Input sentence: Be nice.\n",
            "Decoded sentence: Sois gentil !\n",
            "\n",
            "-\n",
            "Input sentence: Be nice.\n",
            "Decoded sentence: Sois gentil !\n",
            "\n",
            "-\n",
            "Input sentence: Be nice.\n",
            "Decoded sentence: Sois gentil !\n",
            "\n",
            "-\n",
            "Input sentence: Beat it.\n",
            "Decoded sentence: Attendez !\n",
            "\n",
            "-\n",
            "Input sentence: Call me.\n",
            "Decoded sentence: Appelez-le.\n",
            "\n",
            "-\n",
            "Input sentence: Call me.\n",
            "Decoded sentence: Appelez-le.\n",
            "\n",
            "-\n",
            "Input sentence: Call us.\n",
            "Decoded sentence: Appelez-moi !\n",
            "\n",
            "-\n",
            "Input sentence: Call us.\n",
            "Decoded sentence: Appelez-moi !\n",
            "\n",
            "-\n",
            "Input sentence: Come in.\n",
            "Decoded sentence: Entrez !\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7x9z06NnGNu"
      },
      "source": [
        "Но есть проблемы:\n",
        "- на длинных последовательностях результат будет не очень - быстро забывается контекст\n",
        "- хочется научить сеть смотреть в определенное место в прошлом при генерации\n",
        "\n",
        "attention\n",
        "\n",
        "<img src=\"images/Attention.png\"/>\n",
        "\n",
        "<img src=\"images/Attention2.png\"/>\n",
        "\n",
        "\n",
        "- h(t): скрытое состояние декодера\n",
        "- c(t): вектор контекста, который подается на вход\n",
        "- y(t): текущий таргет\n",
        "- $\\bar{h}(t)$: скрытое состояние attention\n",
        "- a(t): скор нормализации\n",
        "\n",
        "\n",
        "$$\\bar{h}(t)\\ =\\ tanh(W_c\\ [c_t,\\ h_t]) $$\n",
        "\n",
        "$$P(y_t|y_{<t},\\ x)\\ =\\ softmax(W_s\\ \\bar{h}_t) $$\n",
        "\n",
        "\n",
        "Зачем нужен скор нормализации? - пытаемся сравнить похожесть текущего скрытого состояния и скрытого состояния из прошлого и понять, на что обращать внимание\n",
        "\n",
        "\n",
        "$$a_t(s)\\ =\\ \\frac{exp(score(h_t,\\ \\bar{h}_s))}{\\sum_{i}\\ exp(score(h_t,\\ \\bar{h}_i)) }$$ \n",
        "\n",
        "\n",
        "<img src=\"images/scores.png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcdoEhvUnGNv"
      },
      "source": [
        "## Поднимемся на уровень слов, чтобы можно было что-то более адекватное посчитать за адекватное время"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RrGR5sYnGNw"
      },
      "source": [
        "import re\n",
        "import tensorflow as tf\n",
        "data_path = '/content/drive/My Drive/Нейронные сети/Neural Language Processing/Lesson 7/Lesson 07/data/fra-eng/fra.txt'\n",
        "num_samples = 10000\n",
        "\n",
        "# tf.enable_eager_execution() # нужно только для тф<2\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    w = w.strip()\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(preprocess_sentence(input_text))\n",
        "    target_texts.append(preprocess_sentence(target_text))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY8eA5l_nGN2"
      },
      "source": [
        "def tokenize(lang):\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "    return tensor, lang_tokenizer"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzldqdP9nGN7"
      },
      "source": [
        "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
        "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6tuBS2-nGOD"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRg3fWV1nGOK"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "\n",
        "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
        "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp-ZEqXmnGOQ"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.lstm(x, initial_state = hidden)\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "    \n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "    \n",
        "    \n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state = self.lstm(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "        return x, state, attention_weights"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7Cu3Uc7nGOV"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmSfFWaYnGOb"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "    \n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXtyDtgZnGOi",
        "outputId": "4710b319-0846-4cae-c944-36fa3ea80620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 1.6333\n",
            "Epoch 2 Loss 1.2027\n",
            "Epoch 3 Loss 0.9973\n",
            "Epoch 4 Loss 0.8534\n",
            "Epoch 5 Loss 0.7371\n",
            "Epoch 6 Loss 0.6292\n",
            "Epoch 7 Loss 0.5372\n",
            "Epoch 8 Loss 0.4508\n",
            "Epoch 9 Loss 0.3778\n",
            "Epoch 10 Loss 0.3144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU6UsayNnGOn"
      },
      "source": [
        "Некоторые украденные функции для оценки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwm26_iwnGOo"
      },
      "source": [
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result, sentence, attention_plot\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    fontdict = {'fontsize': 14}\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()\n",
        "    \n",
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEJXnq1CnGOs"
      },
      "source": [
        "# %pylab inline\n",
        "\n",
        "# translate(u'good morning')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V164yFW3nGOx"
      },
      "source": [
        "# Transformer\n",
        "\n",
        "<img src=\"images/transformer.png\"/>\n",
        "\n",
        "\n",
        "Идея в том, что каждое слово параллельно проходит через слои, изображенные на картинке.\n",
        "Некоторые из них — это стандартные fully-connected layers, некоторые — shortcut connections как в ResNet (там, где на картинке Add).\n",
        "\n",
        "\n",
        "Multi-head attention - это специальный новый слой, который дает возможность каждому входному вектору взаимодействовать с другими словами через attention mechanism, вместо передачи hidden state как в RNN или соседних слов как в CNN.\n",
        "\n",
        "\n",
        "<img src=\"images/mha.png\"/>\n",
        "\n",
        "\n",
        "<img src=\"images/AttTr.png\"/>\n",
        "\n",
        "\n",
        "Работа энкодера:\n",
        "\n",
        "\n",
        "Делаются эмбеддинги для всех слов предложения (вектора одинаковой размерности). Для примера пусть это будет предложение I am stupid. В эмбеддинг добавляется еще позиция слова в предложении.\n",
        "\n",
        "\n",
        "Берется вектор первого слова и вектор второго слова (I, am), подаются на однослойную сеть с одним выходом, которая выдает степень их похожести (скалярная величина). Эта скалярная величина умножается на вектор второго слова, получая его некоторую \"ослабленную\" на величину похожести копию.\n",
        "\n",
        "\n",
        "Вместо второго слова подается третье слово и делается тоже самое что в п.2. с той же самой сетью с теми же весами (для векторов I, stupid).\n",
        "\n",
        "\n",
        "Делая тоже самое для всех оставшихся слов предложения получаются их \"ослабленные\" (взвешенные) копии, которые выражают степень их похожести на первое слово. Далее эти все взвешенные вектора складываются друг с другом, получая один результирующий вектор размерности одного эмбединга:\n",
        "output=am * weight(I, am) + stupid * weight(I, stupid)\n",
        "\n",
        "\n",
        "Это механизм \"обычного\" attention.\n",
        "Так как оценка похожести слов всего одним способом (по одному критерию) считается недостаточной, тоже самое (п.2-4) повторяется несколько раз с другими весами. Типа одна один attention может определять похожесть слов по смысловой нагрузке, другой по грамматической, остальные еще как-то и т.п.\n",
        "\n",
        "\n",
        "На выходе п.5. получается несколько векторов, каждый из которых является взвешенной суммой всех остальных слов предложения относительно их похожести на первое слово (I). Конкантенируем этот вректор в один.\n",
        "\n",
        "\n",
        "Дальше ставится еще один слой линейного преобразования, уменьшающий размерность результата п.6. до размерности вектора одного эмбединга. Получается некое представление первого слова предложения, составленное из взвешенных векторов всех остальных слов предложения.\n",
        "\n",
        "\n",
        "Такой же процесс производится для всех других слов в предложении.\n",
        "\n",
        "\n",
        "Так как размерность выхода та же, то можно проделать все тоже самое еще раз (п.2-8), но вместо оригинальных эмбеддингов слов взять то, что получается после прохода через этот Multi-head attention, а нейросети аттеншенов внутри взять с другими весами (веса между слоями не общие). И таких слоев можно сделать много (у гугла 6). Однако между первым и вторым слоем добавляется еще полносвязный слой и residual соединения, чтобы добавить сети выразительности."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-41Gd7p_nGOy"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "    \"\"\"\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "    return output, attention_weights"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TuGJTrgnGPF"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, \n",
        "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights\n",
        "    \n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYlNLaLunGPL"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, training, mask):\n",
        "\n",
        "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2\n",
        "    \n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    \n",
        "    def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(\n",
        "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2\n",
        "    \n",
        "    \n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                                self.d_model)\n",
        "\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                           for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "    def call(self, x, training, mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        # adding embedding and position encoding.\n",
        "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYzhSLS5nGPS"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                           for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                                 look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        # x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfc6fLSXnGPW"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                               input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                               target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "    def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "        return final_output, attention_weights"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIabkvLHnGPa"
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = len(inp_lang_tokenizer.index_word) + 2\n",
        "target_vocab_size = len(targ_lang_tokenizer.index_word) + 2\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcfuQBMPnGPf"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKCSFdIOnGPl"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "  \n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kags78YYnGPp"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj658qCInGPt"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')\n",
        "\n",
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi71noX_nGPw"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5UxDTmUnGP0"
      },
      "source": [
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "  \n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  \n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "    train_loss(loss)\n",
        "    train_accuracy(tar_real, predictions)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu_6gT2VnGP4",
        "outputId": "de6246a3-2d55-428a-f94f-6872aff72aaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask  # (seq_len, seq_len)\n",
        "\n",
        "for epoch in range(100):\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "  \n",
        "    for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        train_step(inp, tar)\n",
        "        if batch % 50 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "    \n",
        "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 8.2145 Accuracy 0.0000\n",
            "Epoch 1 Batch 50 Loss 8.0596 Accuracy 0.0141\n",
            "Epoch 1 Batch 100 Loss 7.8139 Accuracy 0.0401\n",
            "Epoch 1 Loss 7.7192 Accuracy 0.0453\n",
            "Epoch 2 Batch 0 Loss 7.2099 Accuracy 0.0677\n",
            "Epoch 2 Batch 50 Loss 7.0540 Accuracy 0.0671\n",
            "Epoch 2 Batch 100 Loss 6.8307 Accuracy 0.0718\n",
            "Epoch 2 Loss 6.7047 Accuracy 0.0795\n",
            "Epoch 3 Batch 0 Loss 5.9826 Accuracy 0.1156\n",
            "Epoch 3 Batch 50 Loss 5.7252 Accuracy 0.1165\n",
            "Epoch 3 Batch 100 Loss 5.4638 Accuracy 0.1192\n",
            "Epoch 3 Loss 5.3487 Accuracy 0.1210\n",
            "Epoch 4 Batch 0 Loss 4.7120 Accuracy 0.1271\n",
            "Epoch 4 Batch 50 Loss 4.5434 Accuracy 0.1402\n",
            "Epoch 4 Batch 100 Loss 4.3772 Accuracy 0.1488\n",
            "Epoch 4 Loss 4.3040 Accuracy 0.1516\n",
            "Epoch 5 Batch 0 Loss 3.9269 Accuracy 0.1688\n",
            "Epoch 5 Batch 50 Loss 3.7640 Accuracy 0.1726\n",
            "Epoch 5 Batch 100 Loss 3.6763 Accuracy 0.1760\n",
            "Epoch 5 Loss 3.6308 Accuracy 0.1783\n",
            "Epoch 6 Batch 0 Loss 3.3719 Accuracy 0.1865\n",
            "Epoch 6 Batch 50 Loss 3.3273 Accuracy 0.1899\n",
            "Epoch 6 Batch 100 Loss 3.2473 Accuracy 0.1933\n",
            "Epoch 6 Loss 3.2232 Accuracy 0.1940\n",
            "Epoch 7 Batch 0 Loss 3.2107 Accuracy 0.1875\n",
            "Epoch 7 Batch 50 Loss 2.9790 Accuracy 0.2029\n",
            "Epoch 7 Batch 100 Loss 2.9476 Accuracy 0.2044\n",
            "Epoch 7 Loss 2.9412 Accuracy 0.2049\n",
            "Epoch 8 Batch 0 Loss 2.6893 Accuracy 0.2250\n",
            "Epoch 8 Batch 50 Loss 2.7402 Accuracy 0.2140\n",
            "Epoch 8 Batch 100 Loss 2.7217 Accuracy 0.2140\n",
            "Epoch 8 Loss 2.7141 Accuracy 0.2141\n",
            "Epoch 9 Batch 0 Loss 2.4639 Accuracy 0.2135\n",
            "Epoch 9 Batch 50 Loss 2.5547 Accuracy 0.2211\n",
            "Epoch 9 Batch 100 Loss 2.5351 Accuracy 0.2206\n",
            "Epoch 9 Loss 2.5253 Accuracy 0.2213\n",
            "Epoch 10 Batch 0 Loss 2.4881 Accuracy 0.2167\n",
            "Epoch 10 Batch 50 Loss 2.3692 Accuracy 0.2280\n",
            "Epoch 10 Batch 100 Loss 2.3487 Accuracy 0.2281\n",
            "Epoch 10 Loss 2.3401 Accuracy 0.2287\n",
            "Epoch 11 Batch 0 Loss 2.2199 Accuracy 0.2333\n",
            "Epoch 11 Batch 50 Loss 2.1917 Accuracy 0.2355\n",
            "Epoch 11 Batch 100 Loss 2.1804 Accuracy 0.2358\n",
            "Epoch 11 Loss 2.1705 Accuracy 0.2359\n",
            "Epoch 12 Batch 0 Loss 2.0653 Accuracy 0.2396\n",
            "Epoch 12 Batch 50 Loss 2.0408 Accuracy 0.2406\n",
            "Epoch 12 Batch 100 Loss 2.0229 Accuracy 0.2422\n",
            "Epoch 12 Loss 2.0172 Accuracy 0.2427\n",
            "Epoch 13 Batch 0 Loss 1.8849 Accuracy 0.2719\n",
            "Epoch 13 Batch 50 Loss 1.8953 Accuracy 0.2469\n",
            "Epoch 13 Batch 100 Loss 1.8704 Accuracy 0.2486\n",
            "Epoch 13 Loss 1.8697 Accuracy 0.2486\n",
            "Epoch 14 Batch 0 Loss 1.6734 Accuracy 0.2625\n",
            "Epoch 14 Batch 50 Loss 1.7185 Accuracy 0.2552\n",
            "Epoch 14 Batch 100 Loss 1.7209 Accuracy 0.2556\n",
            "Epoch 14 Loss 1.7311 Accuracy 0.2553\n",
            "Epoch 15 Batch 0 Loss 1.7324 Accuracy 0.2573\n",
            "Epoch 15 Batch 50 Loss 1.5762 Accuracy 0.2641\n",
            "Epoch 15 Batch 100 Loss 1.5970 Accuracy 0.2622\n",
            "Epoch 15 Loss 1.6036 Accuracy 0.2611\n",
            "Epoch 16 Batch 0 Loss 1.4452 Accuracy 0.2625\n",
            "Epoch 16 Batch 50 Loss 1.4697 Accuracy 0.2680\n",
            "Epoch 16 Batch 100 Loss 1.4654 Accuracy 0.2686\n",
            "Epoch 16 Loss 1.4750 Accuracy 0.2678\n",
            "Epoch 17 Batch 0 Loss 1.3304 Accuracy 0.2708\n",
            "Epoch 17 Batch 50 Loss 1.3344 Accuracy 0.2757\n",
            "Epoch 17 Batch 100 Loss 1.3481 Accuracy 0.2754\n",
            "Epoch 17 Loss 1.3530 Accuracy 0.2747\n",
            "Epoch 18 Batch 0 Loss 1.3308 Accuracy 0.2573\n",
            "Epoch 18 Batch 50 Loss 1.2235 Accuracy 0.2842\n",
            "Epoch 18 Batch 100 Loss 1.2374 Accuracy 0.2814\n",
            "Epoch 18 Loss 1.2449 Accuracy 0.2805\n",
            "Epoch 19 Batch 0 Loss 1.1724 Accuracy 0.2740\n",
            "Epoch 19 Batch 50 Loss 1.1092 Accuracy 0.2891\n",
            "Epoch 19 Batch 100 Loss 1.1463 Accuracy 0.2866\n",
            "Epoch 19 Loss 1.1482 Accuracy 0.2862\n",
            "Epoch 20 Batch 0 Loss 0.9353 Accuracy 0.2958\n",
            "Epoch 20 Batch 50 Loss 1.0217 Accuracy 0.2934\n",
            "Epoch 20 Batch 100 Loss 1.0508 Accuracy 0.2916\n",
            "Epoch 20 Loss 1.0643 Accuracy 0.2908\n",
            "Epoch 21 Batch 0 Loss 0.9428 Accuracy 0.3063\n",
            "Epoch 21 Batch 50 Loss 0.9285 Accuracy 0.3012\n",
            "Epoch 21 Batch 100 Loss 0.9624 Accuracy 0.2977\n",
            "Epoch 21 Loss 0.9768 Accuracy 0.2972\n",
            "Epoch 22 Batch 0 Loss 0.8122 Accuracy 0.3063\n",
            "Epoch 22 Batch 50 Loss 0.8551 Accuracy 0.3040\n",
            "Epoch 22 Batch 100 Loss 0.8948 Accuracy 0.3017\n",
            "Epoch 22 Loss 0.9124 Accuracy 0.2998\n",
            "Epoch 23 Batch 0 Loss 0.8406 Accuracy 0.3229\n",
            "Epoch 23 Batch 50 Loss 0.7770 Accuracy 0.3117\n",
            "Epoch 23 Batch 100 Loss 0.8204 Accuracy 0.3065\n",
            "Epoch 23 Loss 0.8343 Accuracy 0.3052\n",
            "Epoch 24 Batch 0 Loss 0.7288 Accuracy 0.3156\n",
            "Epoch 24 Batch 50 Loss 0.7281 Accuracy 0.3143\n",
            "Epoch 24 Batch 100 Loss 0.7661 Accuracy 0.3100\n",
            "Epoch 24 Loss 0.7801 Accuracy 0.3087\n",
            "Epoch 25 Batch 0 Loss 0.5526 Accuracy 0.3448\n",
            "Epoch 25 Batch 50 Loss 0.6856 Accuracy 0.3175\n",
            "Epoch 25 Batch 100 Loss 0.7153 Accuracy 0.3139\n",
            "Epoch 25 Loss 0.7274 Accuracy 0.3126\n",
            "Epoch 26 Batch 0 Loss 0.5667 Accuracy 0.3135\n",
            "Epoch 26 Batch 50 Loss 0.6302 Accuracy 0.3209\n",
            "Epoch 26 Batch 100 Loss 0.6727 Accuracy 0.3175\n",
            "Epoch 26 Loss 0.6894 Accuracy 0.3156\n",
            "Epoch 27 Batch 0 Loss 0.5620 Accuracy 0.3375\n",
            "Epoch 27 Batch 50 Loss 0.6051 Accuracy 0.3238\n",
            "Epoch 27 Batch 100 Loss 0.6384 Accuracy 0.3194\n",
            "Epoch 27 Loss 0.6498 Accuracy 0.3179\n",
            "Epoch 28 Batch 0 Loss 0.5154 Accuracy 0.3406\n",
            "Epoch 28 Batch 50 Loss 0.5748 Accuracy 0.3261\n",
            "Epoch 28 Batch 100 Loss 0.6213 Accuracy 0.3214\n",
            "Epoch 28 Loss 0.6346 Accuracy 0.3195\n",
            "Epoch 29 Batch 0 Loss 0.5575 Accuracy 0.3313\n",
            "Epoch 29 Batch 50 Loss 0.5506 Accuracy 0.3289\n",
            "Epoch 29 Batch 100 Loss 0.5932 Accuracy 0.3222\n",
            "Epoch 29 Loss 0.6133 Accuracy 0.3199\n",
            "Epoch 30 Batch 0 Loss 0.4820 Accuracy 0.3406\n",
            "Epoch 30 Batch 50 Loss 0.5229 Accuracy 0.3300\n",
            "Epoch 30 Batch 100 Loss 0.5734 Accuracy 0.3245\n",
            "Epoch 30 Loss 0.5926 Accuracy 0.3230\n",
            "Epoch 31 Batch 0 Loss 0.5044 Accuracy 0.3219\n",
            "Epoch 31 Batch 50 Loss 0.5224 Accuracy 0.3304\n",
            "Epoch 31 Batch 100 Loss 0.5578 Accuracy 0.3259\n",
            "Epoch 31 Loss 0.5714 Accuracy 0.3247\n",
            "Epoch 32 Batch 0 Loss 0.4295 Accuracy 0.3333\n",
            "Epoch 32 Batch 50 Loss 0.5026 Accuracy 0.3323\n",
            "Epoch 32 Batch 100 Loss 0.5348 Accuracy 0.3277\n",
            "Epoch 32 Loss 0.5521 Accuracy 0.3262\n",
            "Epoch 33 Batch 0 Loss 0.4930 Accuracy 0.3333\n",
            "Epoch 33 Batch 50 Loss 0.4829 Accuracy 0.3349\n",
            "Epoch 33 Batch 100 Loss 0.5240 Accuracy 0.3291\n",
            "Epoch 33 Loss 0.5433 Accuracy 0.3272\n",
            "Epoch 34 Batch 0 Loss 0.4824 Accuracy 0.3135\n",
            "Epoch 34 Batch 50 Loss 0.4609 Accuracy 0.3344\n",
            "Epoch 34 Batch 100 Loss 0.5029 Accuracy 0.3304\n",
            "Epoch 34 Loss 0.5198 Accuracy 0.3283\n",
            "Epoch 35 Batch 0 Loss 0.4281 Accuracy 0.3354\n",
            "Epoch 35 Batch 50 Loss 0.4426 Accuracy 0.3391\n",
            "Epoch 35 Batch 100 Loss 0.4848 Accuracy 0.3321\n",
            "Epoch 35 Loss 0.5016 Accuracy 0.3301\n",
            "Epoch 36 Batch 0 Loss 0.3337 Accuracy 0.3385\n",
            "Epoch 36 Batch 50 Loss 0.4197 Accuracy 0.3391\n",
            "Epoch 36 Batch 100 Loss 0.4533 Accuracy 0.3343\n",
            "Epoch 36 Loss 0.4678 Accuracy 0.3340\n",
            "Epoch 37 Batch 0 Loss 0.4088 Accuracy 0.3438\n",
            "Epoch 37 Batch 50 Loss 0.4179 Accuracy 0.3412\n",
            "Epoch 37 Batch 100 Loss 0.4472 Accuracy 0.3369\n",
            "Epoch 37 Loss 0.4657 Accuracy 0.3341\n",
            "Epoch 38 Batch 0 Loss 0.4057 Accuracy 0.3344\n",
            "Epoch 38 Batch 50 Loss 0.3952 Accuracy 0.3408\n",
            "Epoch 38 Batch 100 Loss 0.4233 Accuracy 0.3381\n",
            "Epoch 38 Loss 0.4349 Accuracy 0.3371\n",
            "Epoch 39 Batch 0 Loss 0.2757 Accuracy 0.3458\n",
            "Epoch 39 Batch 50 Loss 0.3805 Accuracy 0.3417\n",
            "Epoch 39 Batch 100 Loss 0.4162 Accuracy 0.3395\n",
            "Epoch 39 Loss 0.4321 Accuracy 0.3372\n",
            "Epoch 40 Batch 0 Loss 0.3208 Accuracy 0.3333\n",
            "Epoch 40 Batch 50 Loss 0.3657 Accuracy 0.3439\n",
            "Epoch 40 Batch 100 Loss 0.3948 Accuracy 0.3405\n",
            "Epoch 40 Loss 0.4116 Accuracy 0.3393\n",
            "Epoch 41 Batch 0 Loss 0.2617 Accuracy 0.3458\n",
            "Epoch 41 Batch 50 Loss 0.3665 Accuracy 0.3454\n",
            "Epoch 41 Batch 100 Loss 0.3886 Accuracy 0.3428\n",
            "Epoch 41 Loss 0.4021 Accuracy 0.3407\n",
            "Epoch 42 Batch 0 Loss 0.3514 Accuracy 0.3469\n",
            "Epoch 42 Batch 50 Loss 0.3452 Accuracy 0.3466\n",
            "Epoch 42 Batch 100 Loss 0.3767 Accuracy 0.3434\n",
            "Epoch 42 Loss 0.3899 Accuracy 0.3416\n",
            "Epoch 43 Batch 0 Loss 0.3408 Accuracy 0.3344\n",
            "Epoch 43 Batch 50 Loss 0.3448 Accuracy 0.3467\n",
            "Epoch 43 Batch 100 Loss 0.3727 Accuracy 0.3441\n",
            "Epoch 43 Loss 0.3854 Accuracy 0.3422\n",
            "Epoch 44 Batch 0 Loss 0.3170 Accuracy 0.3458\n",
            "Epoch 44 Batch 50 Loss 0.3204 Accuracy 0.3477\n",
            "Epoch 44 Batch 100 Loss 0.3589 Accuracy 0.3438\n",
            "Epoch 44 Loss 0.3693 Accuracy 0.3435\n",
            "Epoch 45 Batch 0 Loss 0.3771 Accuracy 0.3635\n",
            "Epoch 45 Batch 50 Loss 0.3377 Accuracy 0.3466\n",
            "Epoch 45 Batch 100 Loss 0.3567 Accuracy 0.3448\n",
            "Epoch 45 Loss 0.3675 Accuracy 0.3435\n",
            "Epoch 46 Batch 0 Loss 0.3047 Accuracy 0.3583\n",
            "Epoch 46 Batch 50 Loss 0.3177 Accuracy 0.3475\n",
            "Epoch 46 Batch 100 Loss 0.3473 Accuracy 0.3459\n",
            "Epoch 46 Loss 0.3556 Accuracy 0.3449\n",
            "Epoch 47 Batch 0 Loss 0.2822 Accuracy 0.3573\n",
            "Epoch 47 Batch 50 Loss 0.3121 Accuracy 0.3491\n",
            "Epoch 47 Batch 100 Loss 0.3442 Accuracy 0.3462\n",
            "Epoch 47 Loss 0.3563 Accuracy 0.3449\n",
            "Epoch 48 Batch 0 Loss 0.2334 Accuracy 0.3510\n",
            "Epoch 48 Batch 50 Loss 0.3059 Accuracy 0.3507\n",
            "Epoch 48 Batch 100 Loss 0.3321 Accuracy 0.3472\n",
            "Epoch 48 Loss 0.3395 Accuracy 0.3468\n",
            "Epoch 49 Batch 0 Loss 0.2832 Accuracy 0.3500\n",
            "Epoch 49 Batch 50 Loss 0.2960 Accuracy 0.3496\n",
            "Epoch 49 Batch 100 Loss 0.3245 Accuracy 0.3477\n",
            "Epoch 49 Loss 0.3342 Accuracy 0.3470\n",
            "Epoch 50 Batch 0 Loss 0.2348 Accuracy 0.3625\n",
            "Epoch 50 Batch 50 Loss 0.2922 Accuracy 0.3498\n",
            "Epoch 50 Batch 100 Loss 0.3193 Accuracy 0.3486\n",
            "Epoch 50 Loss 0.3298 Accuracy 0.3473\n",
            "Epoch 51 Batch 0 Loss 0.2623 Accuracy 0.3385\n",
            "Epoch 51 Batch 50 Loss 0.2911 Accuracy 0.3526\n",
            "Epoch 51 Batch 100 Loss 0.3144 Accuracy 0.3500\n",
            "Epoch 51 Loss 0.3250 Accuracy 0.3478\n",
            "Epoch 52 Batch 0 Loss 0.2243 Accuracy 0.3688\n",
            "Epoch 52 Batch 50 Loss 0.2783 Accuracy 0.3515\n",
            "Epoch 52 Batch 100 Loss 0.3064 Accuracy 0.3497\n",
            "Epoch 52 Loss 0.3194 Accuracy 0.3483\n",
            "Epoch 53 Batch 0 Loss 0.2351 Accuracy 0.3365\n",
            "Epoch 53 Batch 50 Loss 0.2923 Accuracy 0.3511\n",
            "Epoch 53 Batch 100 Loss 0.3086 Accuracy 0.3485\n",
            "Epoch 53 Loss 0.3183 Accuracy 0.3479\n",
            "Epoch 54 Batch 0 Loss 0.3056 Accuracy 0.3500\n",
            "Epoch 54 Batch 50 Loss 0.2701 Accuracy 0.3531\n",
            "Epoch 54 Batch 100 Loss 0.2980 Accuracy 0.3511\n",
            "Epoch 54 Loss 0.3094 Accuracy 0.3497\n",
            "Epoch 55 Batch 0 Loss 0.2231 Accuracy 0.3677\n",
            "Epoch 55 Batch 50 Loss 0.2657 Accuracy 0.3574\n",
            "Epoch 55 Batch 100 Loss 0.2991 Accuracy 0.3510\n",
            "Epoch 55 Loss 0.3085 Accuracy 0.3496\n",
            "Epoch 56 Batch 0 Loss 0.2422 Accuracy 0.3469\n",
            "Epoch 56 Batch 50 Loss 0.2713 Accuracy 0.3525\n",
            "Epoch 56 Batch 100 Loss 0.2928 Accuracy 0.3513\n",
            "Epoch 56 Loss 0.3025 Accuracy 0.3504\n",
            "Epoch 57 Batch 0 Loss 0.3075 Accuracy 0.3385\n",
            "Epoch 57 Batch 50 Loss 0.2573 Accuracy 0.3541\n",
            "Epoch 57 Batch 100 Loss 0.2828 Accuracy 0.3523\n",
            "Epoch 57 Loss 0.2919 Accuracy 0.3510\n",
            "Epoch 58 Batch 0 Loss 0.2191 Accuracy 0.3417\n",
            "Epoch 58 Batch 50 Loss 0.2591 Accuracy 0.3536\n",
            "Epoch 58 Batch 100 Loss 0.2874 Accuracy 0.3509\n",
            "Epoch 58 Loss 0.2976 Accuracy 0.3507\n",
            "Epoch 59 Batch 0 Loss 0.2310 Accuracy 0.3854\n",
            "Epoch 59 Batch 50 Loss 0.2557 Accuracy 0.3571\n",
            "Epoch 59 Batch 100 Loss 0.2807 Accuracy 0.3530\n",
            "Epoch 59 Loss 0.2924 Accuracy 0.3509\n",
            "Epoch 60 Batch 0 Loss 0.2603 Accuracy 0.3510\n",
            "Epoch 60 Batch 50 Loss 0.2548 Accuracy 0.3551\n",
            "Epoch 60 Batch 100 Loss 0.2798 Accuracy 0.3521\n",
            "Epoch 60 Loss 0.2893 Accuracy 0.3514\n",
            "Epoch 61 Batch 0 Loss 0.2452 Accuracy 0.3521\n",
            "Epoch 61 Batch 50 Loss 0.2538 Accuracy 0.3551\n",
            "Epoch 61 Batch 100 Loss 0.2750 Accuracy 0.3537\n",
            "Epoch 61 Loss 0.2828 Accuracy 0.3525\n",
            "Epoch 62 Batch 0 Loss 0.2072 Accuracy 0.3906\n",
            "Epoch 62 Batch 50 Loss 0.2430 Accuracy 0.3578\n",
            "Epoch 62 Batch 100 Loss 0.2687 Accuracy 0.3544\n",
            "Epoch 62 Loss 0.2776 Accuracy 0.3531\n",
            "Epoch 63 Batch 0 Loss 0.1930 Accuracy 0.3688\n",
            "Epoch 63 Batch 50 Loss 0.2472 Accuracy 0.3562\n",
            "Epoch 63 Batch 100 Loss 0.2653 Accuracy 0.3534\n",
            "Epoch 63 Loss 0.2763 Accuracy 0.3527\n",
            "Epoch 64 Batch 0 Loss 0.1864 Accuracy 0.3625\n",
            "Epoch 64 Batch 50 Loss 0.2443 Accuracy 0.3570\n",
            "Epoch 64 Batch 100 Loss 0.2717 Accuracy 0.3527\n",
            "Epoch 64 Loss 0.2793 Accuracy 0.3521\n",
            "Epoch 65 Batch 0 Loss 0.2177 Accuracy 0.3667\n",
            "Epoch 65 Batch 50 Loss 0.2442 Accuracy 0.3567\n",
            "Epoch 65 Batch 100 Loss 0.2652 Accuracy 0.3547\n",
            "Epoch 65 Loss 0.2716 Accuracy 0.3532\n",
            "Epoch 66 Batch 0 Loss 0.2415 Accuracy 0.3542\n",
            "Epoch 66 Batch 50 Loss 0.2266 Accuracy 0.3566\n",
            "Epoch 66 Batch 100 Loss 0.2567 Accuracy 0.3537\n",
            "Epoch 66 Loss 0.2676 Accuracy 0.3531\n",
            "Epoch 67 Batch 0 Loss 0.2218 Accuracy 0.3583\n",
            "Epoch 67 Batch 50 Loss 0.2346 Accuracy 0.3573\n",
            "Epoch 67 Batch 100 Loss 0.2592 Accuracy 0.3540\n",
            "Epoch 67 Loss 0.2672 Accuracy 0.3536\n",
            "Epoch 68 Batch 0 Loss 0.2232 Accuracy 0.3562\n",
            "Epoch 68 Batch 50 Loss 0.2295 Accuracy 0.3607\n",
            "Epoch 68 Batch 100 Loss 0.2524 Accuracy 0.3560\n",
            "Epoch 68 Loss 0.2617 Accuracy 0.3546\n",
            "Epoch 69 Batch 0 Loss 0.1882 Accuracy 0.3604\n",
            "Epoch 69 Batch 50 Loss 0.2302 Accuracy 0.3590\n",
            "Epoch 69 Batch 100 Loss 0.2504 Accuracy 0.3554\n",
            "Epoch 69 Loss 0.2596 Accuracy 0.3542\n",
            "Epoch 70 Batch 0 Loss 0.2104 Accuracy 0.3552\n",
            "Epoch 70 Batch 50 Loss 0.2268 Accuracy 0.3597\n",
            "Epoch 70 Batch 100 Loss 0.2510 Accuracy 0.3555\n",
            "Epoch 70 Loss 0.2600 Accuracy 0.3543\n",
            "Epoch 71 Batch 0 Loss 0.2023 Accuracy 0.3750\n",
            "Epoch 71 Batch 50 Loss 0.2303 Accuracy 0.3565\n",
            "Epoch 71 Batch 100 Loss 0.2458 Accuracy 0.3554\n",
            "Epoch 71 Loss 0.2563 Accuracy 0.3546\n",
            "Epoch 72 Batch 0 Loss 0.2435 Accuracy 0.3500\n",
            "Epoch 72 Batch 50 Loss 0.2249 Accuracy 0.3568\n",
            "Epoch 72 Batch 100 Loss 0.2457 Accuracy 0.3559\n",
            "Epoch 72 Loss 0.2537 Accuracy 0.3549\n",
            "Epoch 73 Batch 0 Loss 0.2055 Accuracy 0.3677\n",
            "Epoch 73 Batch 50 Loss 0.2207 Accuracy 0.3566\n",
            "Epoch 73 Batch 100 Loss 0.2431 Accuracy 0.3553\n",
            "Epoch 73 Loss 0.2535 Accuracy 0.3544\n",
            "Epoch 74 Batch 0 Loss 0.2005 Accuracy 0.3542\n",
            "Epoch 74 Batch 50 Loss 0.2235 Accuracy 0.3581\n",
            "Epoch 74 Batch 100 Loss 0.2451 Accuracy 0.3558\n",
            "Epoch 74 Loss 0.2533 Accuracy 0.3545\n",
            "Epoch 75 Batch 0 Loss 0.1528 Accuracy 0.3875\n",
            "Epoch 75 Batch 50 Loss 0.2219 Accuracy 0.3584\n",
            "Epoch 75 Batch 100 Loss 0.2417 Accuracy 0.3552\n",
            "Epoch 75 Loss 0.2511 Accuracy 0.3549\n",
            "Epoch 76 Batch 0 Loss 0.2334 Accuracy 0.3781\n",
            "Epoch 76 Batch 50 Loss 0.2243 Accuracy 0.3562\n",
            "Epoch 76 Batch 100 Loss 0.2437 Accuracy 0.3546\n",
            "Epoch 76 Loss 0.2480 Accuracy 0.3550\n",
            "Epoch 77 Batch 0 Loss 0.1773 Accuracy 0.3719\n",
            "Epoch 77 Batch 50 Loss 0.2134 Accuracy 0.3591\n",
            "Epoch 77 Batch 100 Loss 0.2358 Accuracy 0.3558\n",
            "Epoch 77 Loss 0.2439 Accuracy 0.3554\n",
            "Epoch 78 Batch 0 Loss 0.2298 Accuracy 0.3656\n",
            "Epoch 78 Batch 50 Loss 0.2112 Accuracy 0.3573\n",
            "Epoch 78 Batch 100 Loss 0.2341 Accuracy 0.3546\n",
            "Epoch 78 Loss 0.2431 Accuracy 0.3552\n",
            "Epoch 79 Batch 0 Loss 0.1852 Accuracy 0.3615\n",
            "Epoch 79 Batch 50 Loss 0.2106 Accuracy 0.3586\n",
            "Epoch 79 Batch 100 Loss 0.2329 Accuracy 0.3556\n",
            "Epoch 79 Loss 0.2415 Accuracy 0.3550\n",
            "Epoch 80 Batch 0 Loss 0.1929 Accuracy 0.3573\n",
            "Epoch 80 Batch 50 Loss 0.2076 Accuracy 0.3595\n",
            "Epoch 80 Batch 100 Loss 0.2298 Accuracy 0.3568\n",
            "Epoch 80 Loss 0.2408 Accuracy 0.3558\n",
            "Epoch 81 Batch 0 Loss 0.1530 Accuracy 0.3760\n",
            "Epoch 81 Batch 50 Loss 0.2130 Accuracy 0.3580\n",
            "Epoch 81 Batch 100 Loss 0.2314 Accuracy 0.3559\n",
            "Epoch 81 Loss 0.2400 Accuracy 0.3555\n",
            "Epoch 82 Batch 0 Loss 0.1214 Accuracy 0.3781\n",
            "Epoch 82 Batch 50 Loss 0.2059 Accuracy 0.3611\n",
            "Epoch 82 Batch 100 Loss 0.2293 Accuracy 0.3577\n",
            "Epoch 82 Loss 0.2378 Accuracy 0.3557\n",
            "Epoch 83 Batch 0 Loss 0.2226 Accuracy 0.3604\n",
            "Epoch 83 Batch 50 Loss 0.2100 Accuracy 0.3580\n",
            "Epoch 83 Batch 100 Loss 0.2296 Accuracy 0.3561\n",
            "Epoch 83 Loss 0.2375 Accuracy 0.3553\n",
            "Epoch 84 Batch 0 Loss 0.1938 Accuracy 0.3615\n",
            "Epoch 84 Batch 50 Loss 0.2058 Accuracy 0.3592\n",
            "Epoch 84 Batch 100 Loss 0.2264 Accuracy 0.3560\n",
            "Epoch 84 Loss 0.2345 Accuracy 0.3556\n",
            "Epoch 85 Batch 0 Loss 0.1690 Accuracy 0.3625\n",
            "Epoch 85 Batch 50 Loss 0.2016 Accuracy 0.3603\n",
            "Epoch 85 Batch 100 Loss 0.2220 Accuracy 0.3578\n",
            "Epoch 85 Loss 0.2322 Accuracy 0.3559\n",
            "Epoch 86 Batch 0 Loss 0.1802 Accuracy 0.3385\n",
            "Epoch 86 Batch 50 Loss 0.2049 Accuracy 0.3591\n",
            "Epoch 86 Batch 100 Loss 0.2241 Accuracy 0.3567\n",
            "Epoch 86 Loss 0.2319 Accuracy 0.3563\n",
            "Epoch 87 Batch 0 Loss 0.2150 Accuracy 0.3500\n",
            "Epoch 87 Batch 50 Loss 0.2043 Accuracy 0.3623\n",
            "Epoch 87 Batch 100 Loss 0.2236 Accuracy 0.3570\n",
            "Epoch 87 Loss 0.2293 Accuracy 0.3562\n",
            "Epoch 88 Batch 0 Loss 0.1573 Accuracy 0.3667\n",
            "Epoch 88 Batch 50 Loss 0.1976 Accuracy 0.3597\n",
            "Epoch 88 Batch 100 Loss 0.2208 Accuracy 0.3579\n",
            "Epoch 88 Loss 0.2283 Accuracy 0.3566\n",
            "Epoch 89 Batch 0 Loss 0.1689 Accuracy 0.3740\n",
            "Epoch 89 Batch 50 Loss 0.2060 Accuracy 0.3591\n",
            "Epoch 89 Batch 100 Loss 0.2243 Accuracy 0.3571\n",
            "Epoch 89 Loss 0.2308 Accuracy 0.3560\n",
            "Epoch 90 Batch 0 Loss 0.2265 Accuracy 0.3635\n",
            "Epoch 90 Batch 50 Loss 0.2013 Accuracy 0.3602\n",
            "Epoch 90 Batch 100 Loss 0.2148 Accuracy 0.3577\n",
            "Epoch 90 Loss 0.2217 Accuracy 0.3571\n",
            "Epoch 91 Batch 0 Loss 0.1683 Accuracy 0.3823\n",
            "Epoch 91 Batch 50 Loss 0.1996 Accuracy 0.3577\n",
            "Epoch 91 Batch 100 Loss 0.2154 Accuracy 0.3574\n",
            "Epoch 91 Loss 0.2239 Accuracy 0.3565\n",
            "Epoch 92 Batch 0 Loss 0.1564 Accuracy 0.3729\n",
            "Epoch 92 Batch 50 Loss 0.1987 Accuracy 0.3624\n",
            "Epoch 92 Batch 100 Loss 0.2191 Accuracy 0.3573\n",
            "Epoch 92 Loss 0.2248 Accuracy 0.3566\n",
            "Epoch 93 Batch 0 Loss 0.1907 Accuracy 0.3417\n",
            "Epoch 93 Batch 50 Loss 0.1958 Accuracy 0.3595\n",
            "Epoch 93 Batch 100 Loss 0.2126 Accuracy 0.3580\n",
            "Epoch 93 Loss 0.2211 Accuracy 0.3567\n",
            "Epoch 94 Batch 0 Loss 0.1738 Accuracy 0.3552\n",
            "Epoch 94 Batch 50 Loss 0.1924 Accuracy 0.3600\n",
            "Epoch 94 Batch 100 Loss 0.2123 Accuracy 0.3580\n",
            "Epoch 94 Loss 0.2201 Accuracy 0.3571\n",
            "Epoch 95 Batch 0 Loss 0.1760 Accuracy 0.3469\n",
            "Epoch 95 Batch 50 Loss 0.1951 Accuracy 0.3592\n",
            "Epoch 95 Batch 100 Loss 0.2115 Accuracy 0.3580\n",
            "Epoch 95 Loss 0.2190 Accuracy 0.3573\n",
            "Epoch 96 Batch 0 Loss 0.1691 Accuracy 0.3792\n",
            "Epoch 96 Batch 50 Loss 0.1943 Accuracy 0.3595\n",
            "Epoch 96 Batch 100 Loss 0.2121 Accuracy 0.3571\n",
            "Epoch 96 Loss 0.2189 Accuracy 0.3568\n",
            "Epoch 97 Batch 0 Loss 0.1876 Accuracy 0.3573\n",
            "Epoch 97 Batch 50 Loss 0.1934 Accuracy 0.3609\n",
            "Epoch 97 Batch 100 Loss 0.2066 Accuracy 0.3595\n",
            "Epoch 97 Loss 0.2165 Accuracy 0.3572\n",
            "Epoch 98 Batch 0 Loss 0.1788 Accuracy 0.3594\n",
            "Epoch 98 Batch 50 Loss 0.1886 Accuracy 0.3607\n",
            "Epoch 98 Batch 100 Loss 0.2096 Accuracy 0.3578\n",
            "Epoch 98 Loss 0.2177 Accuracy 0.3572\n",
            "Epoch 99 Batch 0 Loss 0.1316 Accuracy 0.3625\n",
            "Epoch 99 Batch 50 Loss 0.1931 Accuracy 0.3609\n",
            "Epoch 99 Batch 100 Loss 0.2115 Accuracy 0.3582\n",
            "Epoch 99 Loss 0.2204 Accuracy 0.3569\n",
            "Epoch 100 Batch 0 Loss 0.1885 Accuracy 0.3542\n",
            "Epoch 100 Batch 50 Loss 0.1859 Accuracy 0.3612\n",
            "Epoch 100 Batch 100 Loss 0.2056 Accuracy 0.3585\n",
            "Epoch 100 Loss 0.2130 Accuracy 0.3575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geXQOB60nGP8",
        "outputId": "eb4708e2-980c-43c1-b01a-94e35fbc1e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def evaluate(inp_sentence):\n",
        "    start_token = [1]\n",
        "    end_token = [2]\n",
        "  \n",
        "    sentence = preprocess_sentence(inp_sentence)\n",
        "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "    \n",
        "    encoder_input = tf.expand_dims(inputs, 0)\n",
        "  \n",
        "  # as the target is english, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "    decoder_input = [1]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "    for i in range(max_length_targ):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "            encoder_input, output)\n",
        "  \n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    \n",
        "    # select the last word from the seq_len dimension\n",
        "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "        if predicted_id == targ_lang_tokenizer.word_index[\"<end>\"]:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "\n",
        "def plot_attention_weights(attention, sentence, result, layer):\n",
        "    fig = plt.figure(figsize=(16, 8))\n",
        "  \n",
        "    sentence = inp_lang_tokenizer.encode(sentence)\n",
        "  \n",
        "    attention = tf.squeeze(attention[layer], axis=0)\n",
        "  \n",
        "    for head in range(attention.shape[0]):\n",
        "        ax = fig.add_subplot(2, 4, head+1)\n",
        "\n",
        "        # plot the attention weights\n",
        "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
        "\n",
        "        fontdict = {'fontsize': 10}\n",
        "\n",
        "        ax.set_xticks(range(len(sentence)+2))\n",
        "        ax.set_yticks(range(len(result)))\n",
        "\n",
        "        ax.set_ylim(len(result)-1.5, -0.5)\n",
        "\n",
        "        ax.set_xticklabels(\n",
        "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
        "            fontdict=fontdict, rotation=90)\n",
        "\n",
        "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
        "                            if i < tokenizer_en.vocab_size], \n",
        "                           fontdict=fontdict)\n",
        "\n",
        "        ax.set_xlabel('Head {}'.format(head+1))\n",
        "  \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def translate(sentence, plot=''):\n",
        "    result, attention_weights = evaluate(sentence)\n",
        "    predicted_sentence = ([targ_lang_tokenizer.index_word[i] for i in result.numpy()])  \n",
        "\n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Predicted translation: {}'.format(predicted_sentence))\n",
        "  \n",
        "    if plot:\n",
        "        plot_attention_weights(attention_weights, sentence, result, plot)\n",
        "        \n",
        "translate(\"good morning.\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: good morning.\n",
            "Predicted translation: ['<start>', 'bonjour', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur3cjnfY7kur"
      },
      "source": [
        ""
      ],
      "execution_count": 55,
      "outputs": []
    }
  ]
}